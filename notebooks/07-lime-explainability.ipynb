{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LIME Explainability for FinBERT\n",
    "\n",
    "This notebook demonstrates LIME (Local Interpretable Model-agnostic Explanations) integration for explaining FinBERT sentiment predictions.\n",
    "\n",
    "**FYP-159: Integrate LIME for sample analysis**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "\n",
    "# Add backend to path\n",
    "sys.path.insert(0, str(Path.cwd().parent / \"backend\"))\n",
    "\n",
    "from app.explainability import LIMEExplainer, get_lime_explainer\n",
    "from app.explainability.visualizations import (\n",
    "    plot_lime_features,\n",
    "    plot_lime_summary_bar,\n",
    "    plot_lime_class_comparison,\n",
    "    save_lime_html,\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.style.use('seaborn-v0_8-darkgrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LIME Explainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize LIME explainer (singleton pattern)\n",
    "explainer = get_lime_explainer(num_features=10, num_samples=1000)\n",
    "print(\"LIME explainer initialized successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 1: Positive Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_positive = \"Stock prices surged to record highs as investors celebrated strong earnings\"\n",
    "\n",
    "# Generate explanation\n",
    "explanation_pos = explainer.explain(text_positive, num_features=10)\n",
    "\n",
    "# Display prediction\n",
    "pred = explanation_pos[\"prediction\"]\n",
    "print(f\"Text: {text_positive}\")\n",
    "print(f\"Prediction: {pred['label'].upper()} ({pred['score']:.1%} confidence)\")\n",
    "print(f\"\\nTop features:\")\n",
    "for feature, weight in explanation_pos[\"top_features\"][:5]:\n",
    "    print(f\"  {feature}: {weight:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plot_lime_features(explanation_pos, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 2: Negative Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_negative = \"Markets crashed following disappointing employment figures and weak economic indicators\"\n",
    "\n",
    "# Generate explanation\n",
    "explanation_neg = explainer.explain(text_negative, num_features=10)\n",
    "\n",
    "# Display prediction\n",
    "pred = explanation_neg[\"prediction\"]\n",
    "print(f\"Text: {text_negative}\")\n",
    "print(f\"Prediction: {pred['label'].upper()} ({pred['score']:.1%} confidence)\")\n",
    "print(f\"\\nTop features:\")\n",
    "for feature, weight in explanation_neg[\"top_features\"][:5]:\n",
    "    print(f\"  {feature}: {weight:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plot_lime_features(explanation_neg, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example 3: Neutral Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_neutral = \"The Federal Reserve announced its decision to maintain current interest rates\"\n",
    "\n",
    "# Generate explanation\n",
    "explanation_neu = explainer.explain(text_neutral, num_features=10)\n",
    "\n",
    "# Display prediction\n",
    "pred = explanation_neu[\"prediction\"]\n",
    "print(f\"Text: {text_neutral}\")\n",
    "print(f\"Prediction: {pred['label'].upper()} ({pred['score']:.1%} confidence)\")\n",
    "print(f\"\\nTop features:\")\n",
    "for feature, weight in explanation_neu[\"top_features\"][:5]:\n",
    "    print(f\"  {feature}: {weight:+.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize\n",
    "plot_lime_features(explanation_neu, figsize=(12, 6))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch Analysis: Multiple Texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define multiple texts for batch analysis\n",
    "texts = [\n",
    "    \"Stock prices surged after earnings beat\",\n",
    "    \"Market crashed on recession fears\",\n",
    "    \"Investors cautious about economic outlook\",\n",
    "    \"Revenue growth exceeded expectations\",\n",
    "    \"Company announced major layoffs\",\n",
    "]\n",
    "\n",
    "# Generate explanations\n",
    "explanations = explainer.explain_batch(texts, num_features=10)\n",
    "\n",
    "# Display results\n",
    "for i, (text, exp) in enumerate(zip(texts, explanations), 1):\n",
    "    if exp:\n",
    "        pred = exp[\"prediction\"]\n",
    "        print(f\"{i}. [{pred['label'].upper():8s}] {pred['score']:.1%} - {text}\")\n",
    "    else:\n",
    "        print(f\"{i}. [FAILED] - {text}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get summary data\n",
    "summary_data = explainer.get_summary_data(explanations, top_n=15)\n",
    "\n",
    "print(f\"Analyzed {summary_data['num_explanations']} texts\")\n",
    "print(f\"\\nTop 10 most important features overall:\")\n",
    "for feature, importance in summary_data['top_features'][:10]:\n",
    "    print(f\"  {feature}: {importance:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot summary bar chart\n",
    "plot_lime_summary_bar(summary_data, top_n=15, figsize=(14, 8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot class comparison\n",
    "plot_lime_class_comparison(summary_data, top_n=10, figsize=(16, 10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export HTML Explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save an explanation as interactive HTML\n",
    "output_path = Path(\"../data/processed/explanations/lime_example_interactive.html\")\n",
    "save_lime_html(explanation_pos, output_path)\n",
    "print(f\"Saved interactive HTML to: {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LIME vs SHAP Comparison\n",
    "\n",
    "Compare LIME and SHAP explanations for the same text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from app.explainability import get_explainer\n",
    "from app.explainability.visualizations import plot_token_contributions\n",
    "\n",
    "# Get SHAP explainer\n",
    "shap_explainer = get_explainer()\n",
    "\n",
    "# Same text for both\n",
    "text = \"Stock prices surged on positive earnings\"\n",
    "\n",
    "# Get explanations\n",
    "lime_exp = explainer.explain(text, num_features=10)\n",
    "shap_exp = shap_explainer.explain(text)\n",
    "\n",
    "print(\"LIME Prediction:\", lime_exp[\"prediction\"][\"label\"].upper())\n",
    "print(\"SHAP Prediction:\", shap_exp[\"prediction\"][\"label\"].upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot side-by-side\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 6))\n",
    "\n",
    "# LIME plot\n",
    "plot_lime_features(lime_exp, show=False)\n",
    "plt.title(\"LIME Explanation\")\n",
    "\n",
    "# SHAP plot\n",
    "plot_token_contributions(shap_exp, show=False)\n",
    "plt.title(\"SHAP Explanation\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "This notebook demonstrated:\n",
    "- ✅ LIME explainer initialization\n",
    "- ✅ Single text explanations (positive, negative, neutral)\n",
    "- ✅ Batch explanations\n",
    "- ✅ Summary visualizations\n",
    "- ✅ Feature importance analysis\n",
    "- ✅ HTML export for interactive exploration\n",
    "- ✅ Comparison with SHAP\n",
    "\n",
    "**FYP-159 Completed**: LIME integration provides token-level sentiment reasoning with visualizations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
